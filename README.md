# vllm-docker
test Llama-3.2-11B-Vision-Instruct 4-bit quant quickly on an a100
